{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_source = '../data/iris.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_source = '../data/mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(iris_source, \n",
    "                  header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_labels = df.drop(columns=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_without_labels, \n",
    "                                                    df.iloc[:,4].tolist(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train = X_test.to_numpy(), X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-c966e7a1fdbf>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-c966e7a1fdbf>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    y_pred = np.array([ majority_voting(self.y_train[knn][i]*w[:,i]) for i in range(len(slef.y_train[knn])) ])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 4: KNN implementation\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class KNearestNeighbors:\n",
    "    def __init__(self, k, distance_metric=\"euclidean\", weights=\"uniform\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Store the 'prior knowledge' of you model that will be used\n",
    "        to predict new labels.\n",
    "        :param X : input data points, ndarray, shape = (R,C).\n",
    "        :param y : input labels, ndarray, shape = (R,).\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        \n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(y)\n",
    "        self.y_train = le.transform(y)\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Run the KNN classification on X.\n",
    "        :param X: input data points, ndarray, shape = (N,C).\n",
    "        :return: labels : ndarray, shape = (N,).\n",
    "        \"\"\"\n",
    "        dist_matrix = compute_distance(self, X)\n",
    "        knn = dist_matrix.argsort(axis=0)[:self.k, :].T\n",
    "        if self.weights=='uniform':\n",
    "            y_pred = np.array([ majority_voting(self.y_train[knn][i]) for i in range(len(self.y_train[knn])) ])\n",
    "\n",
    "\n",
    "        elif self.weights=='distance':\n",
    "            w = 1 / (np.dist_matrix[knn]\n",
    "            #labels = sorted(set(self.y_train))\n",
    "            #lab_counters = [0] * len(labels)\n",
    "            #for lab, w in votes:\n",
    "            #    lab_counters[lab] += w\n",
    "            y_pred = np.array([ majority_voting(self.y_train[knn][i]*w[:,i]) for i in range(len(slef.y_train[knn])) ])\n",
    "                \n",
    "        return y_pred\n",
    "    \n",
    "        \n",
    "    def compute_distance(self, p, q):\n",
    "        if self.distance_metric=='euclidean':\n",
    "            X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "            X_diff = X_train_reshaped - X_test\n",
    "            # shape after diff = (120, 30, 4), \n",
    "            #remember we did reshaping and normalization.\n",
    "            # 4 are the features for iris.data \n",
    "            dist_matrix = np.sqrt(np.sum(X_diff**2,axis=2))\n",
    "            # shape after this op. = (120, 30), axis=2 are the features\n",
    "        \n",
    "        if self.distance_metric=='cosine':\n",
    "            X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "            X_train_norm = ((self.X_train**2).sum(axis=1)**.5).reshape(-1,1)\n",
    "            X_test_norm = ((X_test**2).sum(axis=1)**.5)\n",
    "            dot_prods = self.X_train_reshaped @ X_test.T\n",
    "            dist_matrix = 1 - np.abs(dot_prods / X_train_norm.reshape(-1,1) \n",
    "                                     / X_test_norm)\n",
    "                              \n",
    "        if self.distance_metric=='manhattan':\n",
    "            X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "            X_diff = self.X_train_reshaped - X_test\n",
    "            dist_matrix = np.abs(X_diff).sum(axis=2)\n",
    "\n",
    "        return dist_matrix\n",
    "    \n",
    "    \n",
    "    def compute_accuracy(self, y_pred, y_true):\n",
    "        return (y_true==y_pred).sum() / len(y_true)\n",
    "    \n",
    "    def majority_voting(votes):\n",
    "        count = Counter(votes)\n",
    "        return count.most_common(1)[0][0] \n",
    "        # most_common(n) returns a list with the n most recurring votes (n=1 -> top vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNearestNeighbors(k=8, distance_metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_m[knn].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.take_along_axis(dist_m, knn.T, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.compute_accuracy(y_pred=y_pred, y_test=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 :  New Version: The intuition behind weighted kNN, \n",
    "# is to give more weight to the points which are nearby and \n",
    "#less weight to the points which are farther away.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class KNearestNeighbors:\n",
    "    def __init__(self, k, distance_metric=\"euclidean\", weights=\"uniform\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Store the 'prior knowledge' of you model that will be used\n",
    "        to predict new labels.\n",
    "        :param X : input data points, ndarray, shape = (R,C).\n",
    "        :param y : input labels, ndarray, shape = (R,).\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        \n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(y)\n",
    "        self.y_train = le.transform(y)\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Run the KNN classification on X.\n",
    "        :param X: input data points, ndarray, shape = (N,C).\n",
    "        :return: labels : ndarray, shape = (N,).\n",
    "        \"\"\"\n",
    "        knn = dist_matrix.argsort(axis=0)[:self.k, :].T\n",
    "        if self.weights=='uniform':\n",
    "            y_pred = np.array([ majority_voting(self.y_train[knn][i]) for i in range(len(self.y_train[knn])) ])\n",
    "\n",
    "\n",
    "        elif self.weights=='distance':\n",
    "            votes = [(self.y_train[d[0]], 1/d[1]) for d in dist_list]\n",
    "            labels = sorted(set(self.y_train))\n",
    "            lab_counters = [0] * len(labels)\n",
    "            for lab, w in votes:\n",
    "                lab_counters[lab] += w\n",
    "            lab_counters = np.array(lab_counters)\n",
    "\n",
    "        argmax = np.argmax(lab_counters) # If deuce, we take the first\n",
    "        y_pred.append(argmax)\n",
    "                \n",
    "        return y_pred\n",
    "    \n",
    "        \n",
    "    def compute_distance(self, p, q):\n",
    "        if self.distance_metric=='euclidean':\n",
    "            X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "            X_diff = X_train_reshaped - X_test\n",
    "            # shape after diff = (120, 30, 4), \n",
    "            #remember we did reshaping and normalization.\n",
    "            # 4 are the features for iris.data \n",
    "            dist_matrix = np.sqrt(np.sum(X_diff**2,axis=2))\n",
    "            # shape after this op. = (120, 30), axis=2 are the features\n",
    "        \n",
    "        if self.distance_metric=='cosine':\n",
    "            X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "            X_train_norm = ((self.X_train**2).sum(axis=1)**.5).reshape(-1,1)\n",
    "            X_test_norm = ((X_test**2).sum(axis=1)**.5)\n",
    "            dot_prods = self.X_train_reshaped @ X_test.T\n",
    "            dist_matrix = 1 - np.abs(dot_prods / X_train_norm.reshape(-1,1) \n",
    "                                     / X_test_norm)\n",
    "                              \n",
    "        if self.distance_metric=='manhattan':\n",
    "            X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "            X_diff = self.X_train_reshaped - X_test\n",
    "            dist_matrix = np.abs(X_diff).sum(axis=2)\n",
    "        return dist_matrix\n",
    "    \n",
    "    \n",
    "    def compute_accuracy(self, y_pred, y_true):\n",
    "        return (y_true==y_pred).sum() / len(y_true)\n",
    "    \n",
    "    def _majority_voting(votes):\n",
    "        count = Counter(votes)\n",
    "        return count.most_common(1)[0][0] \n",
    "        # most_common(n) returns a list with the n most recurring votes (n=1 -> top vote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_updated = KNearestNeighbors(k=8, distance_metric='euclidean', weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_updated.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_updated.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_test)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "print(model.compute_accuracy(y_pred=y_pred, y_test=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9: KNN on MNIST\n",
    "import pandas as pd\n",
    "mnist_df = pd.read_csv(mnist_source, \n",
    "                 header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our dataset:\n",
    "labels = mnist_df.iloc[:,0]\n",
    "lab_set = set(labels.tolist())\n",
    "counters = [0] * len(lab_set)\n",
    "dataset = []\n",
    "while any(c < 100 for c in counters):\n",
    "    for i, row in mnist_df.iterrows():\n",
    "        row = row.tolist()\n",
    "        if counters[row[0]] < 100:\n",
    "            dataset.append(row)\n",
    "            counters[row[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_mnist = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(our_mnist.iloc[:, 1:], \n",
    "                                                    our_mnist.iloc[:,0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train = X_test.to_numpy(), X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_KNN = KNearestNeighbors(k=5, distance_metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_KNN.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mnist_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_KNN.compute_accuracy(y_pred=y_pred, y_test=y_test.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
